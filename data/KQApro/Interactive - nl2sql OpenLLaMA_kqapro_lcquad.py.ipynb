{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 3.9.16 (main, Jan 11 2023, 16:05:54)   \n",
    "Type 'copyright', 'credits' or 'license' for more information  \n",
    "IPython 8.10.0 -- An enhanced Interactive Python. Type '?' for help.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_json_file.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 27\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=28'>29</a>\u001b[0m \u001b[39m# Load the JSON file into a dataset\u001b[39;00m\n\u001b[0;32m---> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39myour_json_file.json\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=30'>31</a>\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=32'>33</a>\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=274'>275</a>\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=275'>276</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=276'>277</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=277'>278</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=278'>279</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=279'>280</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=281'>282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_json_file.json'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import os\n",
    "model_id = \"openlm-research/open_llama_7b_v2\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "print(model)\n",
    "\n",
    "\n",
    "# Load the JSON file into a dataset\n",
    "with open(\"your_json_file.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 4\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=27'>28</a>\u001b[0m \u001b[39m# %%\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=28'>29</a>\u001b[0m \u001b[39m# Load the JSON file #into a dataset\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m/home/julio/repos/llm_experiments/data/kqa_lcquad.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m----> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=30'>31</a>\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=32'>33</a>\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(data)\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=35'>36</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(example):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the JSON file #into a dataset\n",
    "with open(\"/home/julio/repos/llm_experiments/data/kqa_lcquad.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.68s/it]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "model_id = \"openlm-research/open_llama_7b_v2\"\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    load_in_8bit=True,\n",
    "    device_map='auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear8bitLt(in_features=11008, out_features=4096, bias=False)\n",
      "          (up_proj): Linear8bitLt(in_features=4096, out_features=11008, bias=False)\n",
      "          (act_fn): SiLUActivation()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 6\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=30'>31</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m/home/julio/repos/llm_experiments/data/kqa_lcquad.json\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=31'>32</a>\u001b[0m     data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m----> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=33'>34</a>\u001b[0m dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39;49mfrom_dict(data)\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=36'>37</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(example):\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=37'>38</a>\u001b[0m     question \u001b[39m=\u001b[39m example[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:900\u001b[0m, in \u001b[0;36mDataset.from_dict\u001b[0;34m(cls, mapping, features, info, split)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=897'>898</a>\u001b[0m features \u001b[39m=\u001b[39m features \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m info\u001b[39m.\u001b[39mfeatures \u001b[39mif\u001b[39;00m info \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=898'>899</a>\u001b[0m arrow_typed_mapping \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=899'>900</a>\u001b[0m \u001b[39mfor\u001b[39;00m col, data \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39;49mitems():\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=900'>901</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)):\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=901'>902</a>\u001b[0m         data \u001b[39m=\u001b[39m cast_array_to_feature(data, features[col]) \u001b[39mif\u001b[39;00m features \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m data\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "# Load the JSON file #into a dataset\n",
    "with open(\"/home/julio/repos/llm_experiments/data/kqa_lcquad.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file #into a dataset\n",
    "with open(\"/home/julio/repos/llm_experiments/data/kqa_lcquad.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert list of dicts to dict of lists\n",
    "data_dict = {key: [d[key] for d in data] for key in data[0].keys()}\n",
    "\n",
    "dataset = Dataset.from_dict(data_dict)\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SPARQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 95376/95376 [00:02<00:00, 33048.38 examples/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Column train not in the dataset. Current columns in the dataset: ['question', 'sparql', 'text']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 4\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=44'>45</a>\u001b[0m \u001b[39m#%%\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=46'>47</a>\u001b[0m mapped_dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mmap(generate_prompt)\n\u001b[0;32m----> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=47'>48</a>\u001b[0m \u001b[39mprint\u001b[39m(mapped_dataset[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:2803\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2800'>2801</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):  \u001b[39m# noqa: F811\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2801'>2802</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2802'>2803</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem(key)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py:2787\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2784'>2785</a>\u001b[0m format_kwargs \u001b[39m=\u001b[39m format_kwargs \u001b[39mif\u001b[39;00m format_kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2785'>2786</a>\u001b[0m formatter \u001b[39m=\u001b[39m get_formatter(format_type, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\u001b[39m.\u001b[39mfeatures, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mformat_kwargs)\n\u001b[0;32m-> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2786'>2787</a>\u001b[0m pa_subtable \u001b[39m=\u001b[39m query_table(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, key, indices\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_indices \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2787'>2788</a>\u001b[0m formatted_output \u001b[39m=\u001b[39m format_table(\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2788'>2789</a>\u001b[0m     pa_subtable, key, formatter\u001b[39m=\u001b[39mformatter, format_columns\u001b[39m=\u001b[39mformat_columns, output_all_columns\u001b[39m=\u001b[39moutput_all_columns\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2789'>2790</a>\u001b[0m )\n\u001b[1;32m   <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/arrow_dataset.py?line=2790'>2791</a>\u001b[0m \u001b[39mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py:580\u001b[0m, in \u001b[0;36mquery_table\u001b[0;34m(table, key, indices)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=577'>578</a>\u001b[0m     _raise_bad_key_type(key)\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=578'>579</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=579'>580</a>\u001b[0m     _check_valid_column_key(key, table\u001b[39m.\u001b[39;49mcolumn_names)\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=580'>581</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=581'>582</a>\u001b[0m     size \u001b[39m=\u001b[39m indices\u001b[39m.\u001b[39mnum_rows \u001b[39mif\u001b[39;00m indices \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m table\u001b[39m.\u001b[39mnum_rows\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py:520\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[0;34m(key, columns)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=517'>518</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_valid_column_key\u001b[39m(key: \u001b[39mstr\u001b[39m, columns: List[\u001b[39mstr\u001b[39m]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=518'>519</a>\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m columns:\n\u001b[0;32m--> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/datasets/formatting/formatting.py?line=519'>520</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mColumn \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[39m{\u001b[39;00mcolumns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Column train not in the dataset. Current columns in the dataset: ['question', 'sparql', 'text']\""
     ]
    }
   ],
   "source": [
    "mapped_dataset = dataset.map(generate_prompt)\n",
    "print(mapped_dataset['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?', 'sparql': 'SELECT DISTINCT ?e WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"town\" . ?e <TOID> ?pv . ?pv <pred:value> \"4000000074573917\" . ?e <OS_grid_reference> ?pv_1 . ?pv_1 <pred:value> \"SP8778\" .  }', 'text': '### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\nWhich town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?\\n\\n### SPARQL:\\nSELECT DISTINCT ?e WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"town\" . ?e <TOID> ?pv . ?pv <pred:value> \"4000000074573917\" . ?e <OS_grid_reference> ?pv_1 . ?pv_1 <pred:value> \"SP8778\" .  }'}\n"
     ]
    }
   ],
   "source": [
    "print(mapped_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/train_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 11\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=34'>35</a>\u001b[0m     \u001b[39m# Convert list of dicts to dict of lists\u001b[39;00m\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=35'>36</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {key: [d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m data] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys()}\n\u001b[0;32m---> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=38'>39</a>\u001b[0m train_data \u001b[39m=\u001b[39m load_data_from_file(\u001b[39m\"\u001b[39;49m\u001b[39m/path/to/train_data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=39'>40</a>\u001b[0m test_data \u001b[39m=\u001b[39m load_data_from_file(\u001b[39m\"\u001b[39m\u001b[39m/path/to/test_data.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=41'>42</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(train_data)\n",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 5\u001b[0m, in \u001b[0;36mload_data_from_file\u001b[0;34m(file_path)\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=31'>32</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data_from_file\u001b[39m(file_path):\n\u001b[0;32m----> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=32'>33</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(file_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=33'>34</a>\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m      <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=34'>35</a>\u001b[0m     \u001b[39m# Convert list of dicts to dict of lists\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=274'>275</a>\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=275'>276</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=276'>277</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=277'>278</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=278'>279</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=279'>280</a>\u001b[0m     )\n\u001b[0;32m--> <a href='file:///home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/IPython/core/interactiveshell.py?line=281'>282</a>\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/train_data.json'"
     ]
    }
   ],
   "source": [
    "def load_data_from_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # Convert list of dicts to dict of lists\n",
    "    return {key: [d[key] for d in data] for key in data[0].keys()}\n",
    "\n",
    "\n",
    "train_data = load_data_from_file(\"/path/to/train_data.json\")\n",
    "test_data = load_data_from_file(\"/path/to/test_data.json\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "datasets = datasets.DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SPARQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/julio/repos/llm_experiments/notebooks/nl2sql OpenLLaMA_kqapro_lcquad.py\u001b[0m in \u001b[0;36mline 19\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=43'>44</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(train_data)\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=44'>45</a>\u001b[0m test_dataset \u001b[39m=\u001b[39m Dataset\u001b[39m.\u001b[39mfrom_dict(test_data)\n\u001b[0;32m---> <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=46'>47</a>\u001b[0m datasets \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mDatasetDict({\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m: train_dataset, \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m: test_dataset})\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=50'>51</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_prompt\u001b[39m(example):\n\u001b[1;32m     <a href='file:///home/julio/repos/llm_experiments/notebooks/nl2sql%20OpenLLaMA_kqapro_lcquad.py?line=51'>52</a>\u001b[0m     question \u001b[39m=\u001b[39m example[\u001b[39m'\u001b[39m\u001b[39mquestion\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
     ]
    }
   ],
   "source": [
    "def load_data_from_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # Convert list of dicts to dict of lists\n",
    "    return {key: [d[key] for d in data] for key in data[0].keys()}\n",
    "\n",
    "\n",
    "train_data = load_data_from_file(\n",
    "    \"/home/julio/repos/llm_experiments/data/kqapro_lcquad_train.json\")\n",
    "test_data = load_data_from_file(\n",
    "    \"/home/julio/repos/llm_experiments/data/kqapro_lcquad_test.json\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "datasets = datasets.DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SPARQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "import transformers\n",
    "from transformers import LlamaTokenizer\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForCausalLM\n",
    "import bitsandbytes as bnb\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "model_id = \"openlm-research/open_llama_7b_v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    # Convert list of dicts to dict of lists\n",
    "    return {key: [d[key] for d in data] for key in data[0].keys()}\n",
    "\n",
    "\n",
    "train_data = load_data_from_file(\n",
    "    \"/home/julio/repos/llm_experiments/data/kqapro_lcquad_train.json\")\n",
    "test_data = load_data_from_file(\n",
    "    \"/home/julio/repos/llm_experiments/data/kqapro_lcquad_test.json\")\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "dataset_dict = DatasetDict({\"train\": train_dataset, \"test\": test_dataset})\n",
    "\n",
    "\n",
    "\n",
    "def generate_prompt(example):\n",
    "    question = example['question']\n",
    "    sparql = example[\"sparql\"]\n",
    "    prompt = f\"### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SPARQL:\\n{sparql}\"\n",
    "    return {'text': prompt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 98376/98376 [00:02<00:00, 32881.60 examples/s]\n",
      "Map: 100%|██████████| 12797/12797 [00:00<00:00, 32274.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?', 'sparql': 'SELECT DISTINCT ?e WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"town\" . ?e <TOID> ?pv . ?pv <pred:value> \"4000000074573917\" . ?e <OS_grid_reference> ?pv_1 . ?pv_1 <pred:value> \"SP8778\" .  }', 'text': '### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\nWhich town has a TOID of 4000000074573917 and has an OS grid reference of SP8778?\\n\\n### SPARQL:\\nSELECT DISTINCT ?e WHERE { ?e <pred:instance_of> ?c . ?c <pred:name> \"town\" . ?e <TOID> ?pv . ?pv <pred:value> \"4000000074573917\" . ?e <OS_grid_reference> ?pv_1 . ?pv_1 <pred:value> \"SP8778\" .  }'}\n",
      "{'question': 'Who was the prize winner when Mrs. Miniver got the Academy Award for Best Writing, Adapted Screenplay?', 'sparql': 'SELECT DISTINCT ?qpv WHERE { ?e_1 <pred:name> \"Mrs. Miniver\" . ?e_2 <pred:name> \"Academy Award for Best Writing, Adapted Screenplay\" . ?e_1 <award_received> ?e_2 . [ <pred:fact_h> ?e_1 ; <pred:fact_r> <award_received> ; <pred:fact_t> ?e_2 ] <statement_is_subject_of> ?qpv .  }', 'text': '### INSTRUCTION\\nPlease convert the following context into an SQL query.\\n\\n### CONTEXT:\\nWho was the prize winner when Mrs. Miniver got the Academy Award for Best Writing, Adapted Screenplay?\\n\\n### SPARQL:\\nSELECT DISTINCT ?qpv WHERE { ?e_1 <pred:name> \"Mrs. Miniver\" . ?e_2 <pred:name> \"Academy Award for Best Writing, Adapted Screenplay\" . ?e_1 <award_received> ?e_2 . [ <pred:fact_h> ?e_1 ; <pred:fact_r> <award_received> ; <pred:fact_t> ?e_2 ] <statement_is_subject_of> ?qpv .  }'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mapped_datasets = dataset_dict.map(generate_prompt)\n",
    "print(mapped_datasets[\"train\"][0])\n",
    "print(mapped_datasets[\"test\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from peft import LoraConfig\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "\n",
    "# model_id = \"openlm-research/open_llama_7b\" # utOfMemoryError: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 39.44 GiB total capacity; 885.54 MiB already allocated; 17.44 MiB free; 992.00 MiB\n",
    "\n",
    "\n",
    "qlora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/peft/utils/other.py:104: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 98376/98376 [00:49<00:00, 1972.37 examples/s]\n",
      "Map: 100%|██████████| 12797/12797 [00:06<00:00, 1928.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "\n",
    "\n",
    "supervised_finetuning_trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=mapped_datasets[\"train\"],\n",
    "    eval_dataset=mapped_datasets[\"test\"],\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=1, #1 #using 2,3 gives error \n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-5,#2e-4,\n",
    "        max_steps=2500, #5000\n",
    "        output_dir=\"./SFTOpenLM-Dolly15k\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        fp16=True,\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    peft_config=qlora_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def make_inference(question):\n",
    "  batch = tokenizer(\n",
    "      f\"### INSTRUCTION\\nPlease convert the following context into an SPARQL query.\\n\\n### CONTEXT:\\n{question}\\n\\n### SPARQL:\", return_tensors='pt')\n",
    "\n",
    "  with torch.cuda.amp.autocast():\n",
    "    output_tokens = model.generate(**batch, max_new_tokens=200)\n",
    "\n",
    "  display(Markdown((tokenizer.decode(output_tokens[0], skip_special_tokens=True))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/transformers/generation/utils.py:1448: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n",
      "/home/julio/anaconda3/envs/llm/lib/python3.9/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
      "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### INSTRUCTION\n",
       "Please convert the following context into an SPARQL query.\n",
       "\n",
       "### CONTEXT:\n",
       "Which movie is shorter, Tron: Legacy or Pirates of the Caribbean: The Curse of the Black Pearl?\n",
       "\n",
       "### SPARQL:\n",
       "SELECT ?movie WHERE {\n",
       "  ?movie a <http://dbpedia.org/ontology/Film> .\n",
       "  ?movie <http://dbpedia.org/ontology/length> ?length .\n",
       "  FILTER (?length > 120)\n",
       "  FILTER (?length < 150)\n",
       "}\n",
       "\n",
       "### EXPLANATION\n",
       "\n",
       "The query above is a SPARQL query that returns the movie that is shorter than 150 minutes and longer than 120 minutes.\n",
       "\n",
       "### EXPLANATION\n",
       "\n",
       "The query above is a SPARQL query that returns the movie that is shorter than 150 minutes and longer than 120 minutes.\n",
       "\n",
       "### EXPLANATION\n",
       "\n",
       "The query above is a SPARQL query that returns the movie that is shorter than 150 minutes and longer than 120"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_sparql = \"Which movie is shorter, Tron: Legacy or Pirates of the Caribbean: The Curse of the Black Pearl?\"\n",
    "\n",
    "\n",
    "make_inference(new_sparql)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
